{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cache combined data\n"
     ]
    }
   ],
   "source": [
    "def get_items():\n",
    "  folder_path = '../data/raw'\n",
    "  processed_files = 0\n",
    "  for file_name in os.listdir(folder_path):\n",
    "    if not file_name.endswith('.zip'):\n",
    "      continue\n",
    "    zip_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "      file_items_name = f'{file_name.removesuffix('.zip')}_NotaFiscalItem.csv'\n",
    "      with zip_ref.open(file_items_name) as file:\n",
    "        file.seek(0)\n",
    "        data_frame = pandas.read_csv(file, delimiter=';', encoding='latin1')\n",
    "        data_frame.rename(columns={\n",
    "          'CHAVE DE ACESSO': 'access_key',\n",
    "          'DATA EMISSÃO': 'emission_date',\n",
    "          'CPF/CNPJ Emitente': 'emission_owner',\n",
    "          'NÚMERO PRODUTO': 'product_index',\n",
    "          'DESCRIÇÃO DO PRODUTO/SERVIÇO': 'description',\n",
    "          'CÓDIGO NCM/SH': 'ncm',\n",
    "          'NCM/SH (TIPO DE PRODUTO)': 'ncm_description',\n",
    "          'CFOP': 'cfop',\n",
    "          'QUANTIDADE': 'quantity',\n",
    "          'UNIDADE': 'unit_kind',\n",
    "          'VALOR UNITÁRIO': 'unitary_value',\n",
    "          'VALOR TOTAL': 'total_value',\n",
    "        }, inplace=True)\n",
    "        selected_fields = data_frame \\\n",
    "          .loc[:, [\n",
    "            'access_key',\n",
    "            'emission_date',\n",
    "            'emission_owner',\n",
    "            'product_index',\n",
    "            'description',\n",
    "            'ncm',\n",
    "            'ncm_description',\n",
    "            'cfop',\n",
    "            'quantity',\n",
    "            'unit_kind',\n",
    "            'unitary_value',\n",
    "            'total_value',\n",
    "          ]]\n",
    "        selected_fields['quantity'] = selected_fields['quantity'].str.replace(',', '.')\n",
    "        selected_fields['total_value'] = selected_fields['total_value'].str.replace(',', '.')\n",
    "        selected_fields['unitary_value'] = selected_fields['unitary_value'].str.replace(',', '.')\n",
    "        yield selected_fields \\\n",
    "          .astype({\n",
    "            'access_key': 'str',\n",
    "            'emission_date': 'datetime64[ms]',\n",
    "            'emission_owner': 'str',\n",
    "            'product_index': 'int32',\n",
    "            'description': 'str',\n",
    "            'ncm': 'str',\n",
    "            'ncm_description': 'str',\n",
    "            'cfop': 'str',\n",
    "            'quantity': 'float64',\n",
    "            'unit_kind': 'str',\n",
    "            'unitary_value': 'float64',\n",
    "            'total_value': 'float64',\n",
    "          })\n",
    "        processed_files += 1\n",
    "        print(f'Processed files {processed_files}')\n",
    "\n",
    "\n",
    "def get_combined():\n",
    "  combined_path = '../data/combined.parquet.br'\n",
    "  if os.path.exists(combined_path):\n",
    "    print('Reading cache combined data')\n",
    "    return pandas.read_parquet(combined_path)\n",
    "  combined_data = pandas.concat(get_items(), ignore_index=True)\n",
    "  print('Start compression')\n",
    "  combined_data.to_parquet(combined_path, index=False, compression='brotli')\n",
    "  return combined_data\n",
    "\n",
    "data_frame = get_combined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17752229 entries, 0 to 17752228\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   access_key       object        \n",
      " 1   emission_date    datetime64[ms]\n",
      " 2   emission_owner   object        \n",
      " 3   product_index    int32         \n",
      " 4   description      object        \n",
      " 5   ncm              object        \n",
      " 6   ncm_description  object        \n",
      " 7   cfop             object        \n",
      " 8   quantity         float64       \n",
      " 9   unit_kind        object        \n",
      " 10  unitary_value    float64       \n",
      " 11  total_value      float64       \n",
      "dtypes: datetime64[ms](1), float64(3), int32(1), object(7)\n",
      "memory usage: 1.5+ GB\n",
      "Total rows: 17752229\n",
      "Unique rows: 17673249\n",
      "Removed rows: 78980\n",
      "Removed rows percentage: 0.0044%\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(data_frame)\n",
    "data_frame.info() \n",
    "\n",
    "data_frame.drop_duplicates(inplace=True)\n",
    "\n",
    "unique_rows = len(data_frame)\n",
    "removed_rows = total_rows - unique_rows\n",
    "print(f'Total rows: {total_rows}')\n",
    "print(f'Unique rows: {unique_rows}')\n",
    "print(f'Removed rows: {removed_rows}')\n",
    "print(f'Removed rows percentage: {round(removed_rows / total_rows, 4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dict(map(lambda x: (str(x), {'unique': 0}), range(0, 100)))\n",
    "for table_item in data_frame['access_key'].unique():\n",
    "  table[table_item[0:2]]['unique'] += 1\n",
    "  \n",
    "table = dict(filter(lambda x: x[1]['unique'] > 0, table.items()))\n",
    "for key in table.keys():\n",
    "  current_state = data_frame.where(data_frame['access_key'].str.startswith(key))\n",
    "  total_value = current_state['total_value']\n",
    "  table[key] |= {\n",
    "    'total': total_value.count(),\n",
    "    'total_value': round(total_value.sum(), 2),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = dict(map(\n",
    "  lambda x: (str(x['id']), x),\n",
    "  requests.get('https://servicodados.ibge.gov.br/api/v1/localidades/estados').json(),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP\tSão Paulo\t968.433\t4.372.236\t99.859.384.457\n",
      "RJ\tRio de Janeiro\t849.573\t2.581.830\t46.588.402.728\n",
      "RS\tRio Grande do Sul\t426.544\t1.904.333\t8.236.053.721\n",
      "MG\tMinas Gerais\t353.555\t1.342.135\t18.058.849.286\n",
      "DF\tDistrito Federal\t385.766\t1.063.719\t15.600.639.407\n",
      "PR\tParaná\t272.867\t943.222\t8.510.054.005\n",
      "SC\tSanta Catarina\t223.651\t575.369\t5.383.060.717\n",
      "PE\tPernambuco\t147.843\t510.864\t6.940.477.382\n",
      "BA\tBahia\t112.289\t442.067\t1.592.486.551\n",
      "MS\tMato Grosso do Sul\t91.216\t420.025\t945.018.198\n",
      "PA\tPará\t101.956\t407.554\t1.028.692.878\n",
      "AM\tAmazonas\t99.436\t397.293\t1.335.224.610\n",
      "RN\tRio Grande do Norte\t97.188\t330.951\t449.921.854\n",
      "GO\tGoiás\t119.522\t322.409\t23.389.753.224\n",
      "CE\tCeará\t83.192\t290.382\t672.199.675\n",
      "MA\tMaranhão\t72.172\t287.946\t381.705.137\n",
      "ES\tEspírito Santo\t89.008\t250.336\t3.452.116.826\n",
      "MT\tMato Grosso\t106.433\t247.252\t490.956.647\n",
      "PB\tParaíba\t59.998\t173.599\t463.042.991\n",
      "PI\tPiauí\t35.788\t170.278\t220.885.632\n",
      "RO\tRondônia\t48.759\t156.884\t371.488.485\n",
      "RR\tRoraima\t26.410\t121.510\t598.998.213\n",
      "AC\tAcre\t22.273\t87.804\t132.491.524\n",
      "AL\tAlagoas\t27.815\t82.120\t229.591.047\n",
      "AP\tAmapá\t18.047\t72.045\t87.334.886\n",
      "TO\tTocantins\t19.816\t64.543\t126.683.656\n",
      "SE\tSergipe\t18.134\t54.543\t165.637.349\n"
     ]
    }
   ],
   "source": [
    "meta_table_rows = list(table.items())\n",
    "meta_table_rows.sort(key=lambda x: x[1]['total'], reverse=True)\n",
    "for key, value in meta_table_rows:\n",
    "  print('\\t'.join([\n",
    "    state_codes.get(key)['sigla'],\n",
    "    state_codes.get(key)['nome'],\n",
    "    \"{:,}\".format(value['unique']),\n",
    "    \"{:,}\".format(value['total']),\n",
    "    \"{:,}\".format(int(value['total_value'])),\n",
    "  ]).replace(',', '.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
